{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a DataFrame from reading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.rdd.RDD\n",
       "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
       "import org.apache.spark.{SparkConf, SparkContext}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.spark.sql.{DataFrame, Row, SparkSession}\n",
    "import org.apache.spark.{SparkConf, SparkContext}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_data: String = /Users/soda/Documents/GitHub/joutatsu-no-kotsu/resources/question_tags_10K.csv\n",
       "dfTags: org.apache.spark.sql.DataFrame = [id: int, tag: string]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path_data = \"/Users/soda/Documents/GitHub/joutatsu-no-kotsu/resources/question_tags_10K.csv\"\n",
    "val dfTags = spark\n",
    "    .read\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .csv(path_data)\n",
    "    .toDF(\"id\",\"tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|                tag|\n",
      "+---+-------------------+\n",
      "|  1|               data|\n",
      "|  4|                 c#|\n",
      "|  4|           winforms|\n",
      "|  4|    type-conversion|\n",
      "|  4|            decimal|\n",
      "|  4|            opacity|\n",
      "|  6|               html|\n",
      "|  6|                css|\n",
      "|  6|               css3|\n",
      "|  6|internet-explorer-7|\n",
      "+---+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTags.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTags.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|                tag|\n",
      "+-------------------+\n",
      "|               data|\n",
      "|                 c#|\n",
      "|           winforms|\n",
      "|    type-conversion|\n",
      "|            decimal|\n",
      "|            opacity|\n",
      "|               html|\n",
      "|                css|\n",
      "|               css3|\n",
      "|internet-explorer-7|\n",
      "+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: select columns from a dataframe\n",
    "dfTags.select(\"tag\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|tag|\n",
      "+---+---+\n",
      "| 23|php|\n",
      "| 42|php|\n",
      "| 85|php|\n",
      "|126|php|\n",
      "|146|php|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: filter by column value of a dataframe\n",
    "dfTags.filter(\"tag=='php'\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of php tags = 133\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: count rows of a dataframe\n",
    "println(s\"Number of php tags = ${dfTags.filter(\"tag == 'php'\").count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|          tag|\n",
      "+---+-------------+\n",
      "| 25|      sockets|\n",
      "| 36|          sql|\n",
      "| 36|   sql-server|\n",
      "| 40| structuremap|\n",
      "| 48|submit-button|\n",
      "+---+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: SQL like query\n",
    "dfTags.filter(\"tag like 's%'\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|    tag|\n",
      "+---+-------+\n",
      "| 25|sockets|\n",
      "|108|    svn|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: Multiple filter chaining\n",
    "dfTags\n",
    "    .filter(\"tag like 's%'\")\n",
    "    .filter(\"id == 25 or id == 108\")\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|      tag|\n",
      "+---+---------+\n",
      "| 25|      c++|\n",
      "| 25|        c|\n",
      "| 25|  sockets|\n",
      "| 25|mainframe|\n",
      "| 25|      zos|\n",
      "+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: SQL IN clause\n",
    "dfTags.filter(\"id in (25,108)\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group by tag value\n",
      "+--------------------+-----+\n",
      "|                 tag|count|\n",
      "+--------------------+-----+\n",
      "|         type-safety|    4|\n",
      "|             jbutton|    1|\n",
      "|              iframe|    2|\n",
      "|           svn-hooks|    2|\n",
      "|           standards|    7|\n",
      "|knowledge-management|    2|\n",
      "|            trayicon|    1|\n",
      "|           arguments|    1|\n",
      "|                 zfs|    1|\n",
      "|              import|    3|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: SQL Group By\n",
    "println(\"Group by tag value\")\n",
    "dfTags.groupBy(\"tag\").count().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|          tag|count|\n",
      "+-------------+-----+\n",
      "|    standards|    7|\n",
      "|     keyboard|    8|\n",
      "|          rss|   12|\n",
      "|documentation|   15|\n",
      "|      session|    6|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: SQL Group By with filter\n",
    "dfTags.groupBy(\"tag\").count().filter(\"count > 5\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|     tag|count|\n",
      "+--------+-----+\n",
      "|    .net|  351|\n",
      "|.net-2.0|   14|\n",
      "+--------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: SQL order by\n",
    "dfTags.groupBy(\"tag\").count().filter(\"count >5\")\n",
    "    .orderBy(\"tag\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfQuestionCSV: org.apache.spark.sql.DataFrame = [id: int, creation_date: timestamp ... 5 more fields]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame Query: Cast columns to specific data type\n",
    "val dfQuestionCSV = spark\n",
    "    .read\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"inferSchema\",\"true\")\n",
    "    .option(\"dateFormat\",\"yyyy-MM-dd HH:mm:ss\")\n",
    "    .csv(\"/Users/soda/Documents/GitHub/joutatsu-no-kotsu/resources/questions_10K.csv\")\n",
    "    .toDF(\"id\",\"creation_date\",\"closed_date\", \"deletion_date\", \n",
    "          \"score\", \"owner_userid\", \"answer_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- creation_date: timestamp (nullable = true)\n",
      " |-- closed_date: string (nullable = true)\n",
      " |-- deletion_date: string (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- owner_userid: string (nullable = true)\n",
      " |-- answer_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfQuestionCSV.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----------+--------------------+-----+------------+------------+\n",
      "| id|      creation_date|closed_date|       deletion_date|score|owner_userid|answer_count|\n",
      "+---+-------------------+-----------+--------------------+-----+------------+------------+\n",
      "|  1|2008-08-01 05:26:37|         NA|2011-03-28T00:53:47Z|    1|          NA|           0|\n",
      "|  4|2008-08-01 05:42:52|         NA|                  NA|  472|           8|          13|\n",
      "+---+-------------------+-----------+--------------------+-----+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfQuestionCSV.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfQuestions: org.apache.spark.sql.DataFrame = [id: int, creation_date: timestamp ... 5 more fields]\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfQuestions = dfQuestionCSV.select(\n",
    "    dfQuestionCSV.col(\"id\").cast(\"integer\"),\n",
    "    dfQuestionCSV.col(\"creation_date\").cast(\"timestamp\"),\n",
    "    dfQuestionCSV.col(\"closed_date\").cast(\"timestamp\"),\n",
    "    dfQuestionCSV.col(\"deletion_date\").cast(\"date\"),\n",
    "    dfQuestionCSV.col(\"score\").cast(\"integer\"),\n",
    "    dfQuestionCSV.col(\"owner_userid\").cast(\"integer\"),\n",
    "    dfQuestionCSV.col(\"answer_count\").cast(\"integer\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- creation_date: timestamp (nullable = true)\n",
      " |-- closed_date: timestamp (nullable = true)\n",
      " |-- deletion_date: date (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- owner_userid: integer (nullable = true)\n",
      " |-- answer_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfQuestions.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----------+-------------+-----+------------+------------+\n",
      "| id|      creation_date|closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+---+-------------------+-----------+-------------+-----+------------+------------+\n",
      "|  1|2008-08-01 05:26:37|       null|   2011-03-28|    1|        null|           0|\n",
      "|  4|2008-08-01 05:42:52|       null|         null|  472|           8|          13|\n",
      "|  6|2008-08-01 06:08:08|       null|         null|  210|           9|           5|\n",
      "+---+-------------------+-----------+-------------+-----+------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfQuestions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "|  id|      creation_date|        closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+----+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "| 888|2008-08-04 07:18:21|2016-08-04 17:22:00|         null|  405|         131|          30|\n",
      "|1939|2008-08-05 13:39:36|2012-06-05 21:13:38|   2012-12-18|  408|        null|          48|\n",
      "+----+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfQuestionsSubset: org.apache.spark.sql.DataFrame = [id: int, creation_date: timestamp ... 5 more fields]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame Query: Operate on a sliced dataframe\n",
    "val dfQuestionsSubset = dfQuestions.filter(\"score > 400 and score < 410\").toDF()\n",
    "dfQuestionsSubset.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------------------+-----+\n",
      "|owner_userid|      tag|      creation_date|score|\n",
      "+------------+---------+-------------------+-----+\n",
      "|         131|      php|2008-08-04 07:18:21|  405|\n",
      "|         131|  eclipse|2008-08-04 07:18:21|  405|\n",
      "|         131|debugging|2008-08-04 07:18:21|  405|\n",
      "|         131| phpstorm|2008-08-04 07:18:21|  405|\n",
      "|         131|   xdebug|2008-08-04 07:18:21|  405|\n",
      "+------------+---------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: Join\n",
    "dfQuestionsSubset.join(dfTags,\"id\")\n",
    "    .select(\"owner_userid\",\"tag\",\"creation_date\",\"score\")\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------------------+-----+\n",
      "|owner_userid|      tag|      creation_date|score|\n",
      "+------------+---------+-------------------+-----+\n",
      "|         131|      php|2008-08-04 07:18:21|  405|\n",
      "|         131|  eclipse|2008-08-04 07:18:21|  405|\n",
      "|         131|debugging|2008-08-04 07:18:21|  405|\n",
      "+------------+---------+-------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: Join on explicit columns\n",
    "dfQuestionsSubset\n",
    "    .join(dfTags,dfTags(\"id\")===dfQuestionsSubset(\"id\"))\n",
    "    .select(\"owner_userid\",\"tag\",\"creation_date\",\"score\")\n",
    "    .show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------------------+-----+\n",
      "|owner_userid|      tag|      creation_date|score|\n",
      "+------------+---------+-------------------+-----+\n",
      "|         131|      php|2008-08-04 07:18:21|  405|\n",
      "|         131|  eclipse|2008-08-04 07:18:21|  405|\n",
      "|         131|debugging|2008-08-04 07:18:21|  405|\n",
      "|         131| phpstorm|2008-08-04 07:18:21|  405|\n",
      "|         131|   xdebug|2008-08-04 07:18:21|  405|\n",
      "+------------+---------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: Inner Join\n",
    "dfQuestionsSubset\n",
    "    .join(dfTags,Seq(\"id\"),\"inner\")\n",
    "    .select(\"owner_userid\",\"tag\",\"creation_date\",\"score\")\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------------------+-----+\n",
      "|owner_userid|      tag|      creation_date|score|\n",
      "+------------+---------+-------------------+-----+\n",
      "|         131|   xdebug|2008-08-04 07:18:21|  405|\n",
      "|         131| phpstorm|2008-08-04 07:18:21|  405|\n",
      "|         131|debugging|2008-08-04 07:18:21|  405|\n",
      "|         131|  eclipse|2008-08-04 07:18:21|  405|\n",
      "|         131|      php|2008-08-04 07:18:21|  405|\n",
      "+------------+---------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: Left Outer Join\n",
    "dfQuestionsSubset\n",
    "    .join(dfTags, Seq(\"id\"), \"left_outer\")\n",
    "    .select(\"owner_userid\",\"tag\",\"creation_date\",\"score\")\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        tag|\n",
      "+-----------+\n",
      "|type-safety|\n",
      "|    jbutton|\n",
      "|     iframe|\n",
      "|  svn-hooks|\n",
      "|  standards|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Query: Distinct\n",
    "dfTags.select(\"tag\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Register temp table from dataframe\n",
    "dfTags.createOrReplaceTempView(\"so_tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkSession: org.apache.spark.sql.SparkSession = <lazy>\n"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// trait Context {\n",
    "\n",
    "//   lazy val sparkConf = new SparkConf()\n",
    "//     .setAppName(\"Learn Spark\")\n",
    "//     .setMaster(\"local[*]\")\n",
    "//     .set(\"spark.cores.max\", \"2\")\n",
    "\n",
    "//   lazy val sparkSession = SparkSession\n",
    "//     .builder()\n",
    "//     .config(sparkConf)\n",
    "//     .getOrCreate()\n",
    "// }\n",
    "\n",
    "lazy val sparkSession = SparkSession\n",
    "    .builder()\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------+---------+-----------+\n",
      "|   name|database|description|tableType|isTemporary|\n",
      "+-------+--------+-----------+---------+-----------+\n",
      "|so_tags|    null|       null|TEMPORARY|       true|\n",
      "+-------+--------+-----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// List all tables in Spark's catalog\n",
    "sparkSession.catalog.listTables().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |  so_tags|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// List all tables in Spark's catalog using Spark SQL\n",
    "sparkSession.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|                tag|\n",
      "+---+-------------------+\n",
      "|  1|               data|\n",
      "|  4|                 c#|\n",
      "|  4|           winforms|\n",
      "|  4|    type-conversion|\n",
      "|  4|            decimal|\n",
      "|  4|            opacity|\n",
      "|  6|               html|\n",
      "|  6|                css|\n",
      "|  6|               css3|\n",
      "|  6|internet-explorer-7|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Select columns\n",
    "sparkSession\n",
    "    .sql(\"select id,tag from so_tags limit 10\")\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|tag|\n",
      "+---+---+\n",
      "| 23|php|\n",
      "| 42|php|\n",
      "| 85|php|\n",
      "|126|php|\n",
      "|146|php|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Filter by column value\n",
    "sparkSession.sql(\"select * from so_tags where tag = 'php'\")\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|php_count|\n",
      "+---------+\n",
      "|      133|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Count number of rows\n",
    "sparkSession.sql(\"\"\"\n",
    "    select count(*) as php_count from so_tags\n",
    "        where tag = 'php'\n",
    "                 \"\"\".stripMargin).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|          tag|\n",
      "+---+-------------+\n",
      "| 25|      sockets|\n",
      "| 36|          sql|\n",
      "| 36|   sql-server|\n",
      "| 40| structuremap|\n",
      "| 48|submit-button|\n",
      "| 79|          svn|\n",
      "| 79|    subclipse|\n",
      "| 85|          sql|\n",
      "| 90|          svn|\n",
      "|108|          svn|\n",
      "+---+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL like\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select * from so_tags\n",
    "    where tag like 's%'\n",
    "    \"\"\".stripMargin\n",
    "    ).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|    tag|\n",
      "+---+-------+\n",
      "| 25|sockets|\n",
      "|108|    svn|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL where with and clause\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select * from so_tags\n",
    "    where tag like 's%'\n",
    "    and (id = 25 or id = 108)\n",
    "    \"\"\".stripMargin\n",
    "    ).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|      tag|\n",
      "+---+---------+\n",
      "| 25|      c++|\n",
      "| 25|        c|\n",
      "| 25|  sockets|\n",
      "| 25|mainframe|\n",
      "| 25|      zos|\n",
      "|108|  windows|\n",
      "|108|      svn|\n",
      "|108|    64bit|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL IN clause\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select * from so_tags\n",
    "    where id in (25,108)\n",
    "    \"\"\".stripMargin\n",
    "    ).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|        tag|count|\n",
      "+-----------+-----+\n",
      "|type-safety|    4|\n",
      "|    jbutton|    1|\n",
      "|     iframe|    2|\n",
      "|  svn-hooks|    2|\n",
      "|  standards|    7|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL Group By\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select tag,count(*) as count\n",
    "        from so_tags\n",
    "        group by tag\n",
    "    \"\"\".stripMargin\n",
    "    ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|          tag|count|\n",
      "+-------------+-----+\n",
      "|    standards|    7|\n",
      "|     keyboard|    8|\n",
      "|          rss|   12|\n",
      "|documentation|   15|\n",
      "|      session|    6|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL Group By with having clause\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select tag,count(*) as count\n",
    "    from so_tags \n",
    "    group by tag\n",
    "    having count > 5\n",
    "    \"\"\".stripMargin\n",
    "    ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|          tag|count|\n",
      "+-------------+-----+\n",
      "|stackoverflow|  382|\n",
      "|           c#|  375|\n",
      "|         .net|  351|\n",
      "|      asp.net|  185|\n",
      "|   sql-server|  167|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL Order by\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select tag, count(*) as count\n",
    "    from so_tags\n",
    "    group by tag\n",
    "    having count >5\n",
    "    order by count desc\n",
    "    \"\"\".stripMargin\n",
    "    ).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// Typed columns, filter and create temp table\n",
    "dfQuestionsSubset.createOrReplaceTempView(\"so_questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "| id|      tag| id|      creation_date|        closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "|888|   xdebug|888|2008-08-04 07:18:21|2016-08-04 17:22:00|         null|  405|         131|          30|\n",
      "|888| phpstorm|888|2008-08-04 07:18:21|2016-08-04 17:22:00|         null|  405|         131|          30|\n",
      "|888|debugging|888|2008-08-04 07:18:21|2016-08-04 17:22:00|         null|  405|         131|          30|\n",
      "|888|  eclipse|888|2008-08-04 07:18:21|2016-08-04 17:22:00|         null|  405|         131|          30|\n",
      "|888|      php|888|2008-08-04 07:18:21|2016-08-04 17:22:00|         null|  405|         131|          30|\n",
      "+---+---------+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL Inner Join\n",
    "// SQL Left Outer Join\n",
    "// SQL Right Outer Join\n",
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select t.*,q.*\n",
    "    from so_questions as q\n",
    "    inner join so_tags t\n",
    "    on t.id = q.id\n",
    "    \"\"\".stripMargin\n",
    "    ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 tag|\n",
      "+--------------------+\n",
      "|         type-safety|\n",
      "|             jbutton|\n",
      "|              iframe|\n",
      "|           svn-hooks|\n",
      "|           standards|\n",
      "|knowledge-management|\n",
      "|            trayicon|\n",
      "|           arguments|\n",
      "|                 zfs|\n",
      "|              import|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SQL Distinct\n",
    "sparkSession\n",
    "    .sql(\n",
    "        \"\"\"\n",
    "        select distinct tag from so_tags\n",
    "        \"\"\".stripMargin\n",
    "    ).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prefixStackoverflow: (s: String)String\n",
       "res51: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,StringType,Some(List(StringType)))\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// **Register User Defined Function (UDF)**\n",
    "def prefixStackoverflow(s:String):String = s\"so_$s\"\n",
    "\n",
    "sparkSession.udf\n",
    "    .register(\"prefix_so\",prefixStackoverflow _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|UDF:prefix_so(tag)|\n",
      "+---+------------------+\n",
      "|  1|           so_data|\n",
      "|  4|             so_c#|\n",
      "|  4|       so_winforms|\n",
      "|  4|so_type-conversion|\n",
      "|  4|        so_decimal|\n",
      "+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkSession.sql(\n",
    "    \"\"\"\n",
    "    select id, prefix_so(tag) from so_tags\n",
    "    \"\"\".stripMargin\n",
    "    ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "| id|      creation_date|        closed_date|deletion_date|score|owner_userid|answer_count|\n",
      "+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "|  1|2008-08-01 05:26:37|               null|   2011-03-28|    1|        null|           0|\n",
      "|  4|2008-08-01 05:42:52|               null|         null|  472|           8|          13|\n",
      "|  6|2008-08-01 06:08:08|               null|         null|  210|           9|           5|\n",
      "|  8|2008-08-01 07:33:19|2013-06-03 12:00:25|   2015-02-11|   42|        null|           8|\n",
      "+---+-------------------+-------------------+-------------+-----+------------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// DataFrame Statistics Introduction\n",
    "dfQuestions.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(score)|\n",
      "+-----------------+\n",
      "|36.14631463146315|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Average\n",
    "import org.apache.spark.sql.functions._\n",
    "dfQuestions.select(avg(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(score)|\n",
      "+----------+\n",
      "|      4443|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Max\n",
    "dfQuestions.select(max(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(score)|\n",
      "+----------+\n",
      "|       -27|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Minimum\n",
    "dfQuestions.select(min(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(score)|\n",
      "+-----------------+\n",
      "|36.14631463146315|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Mean\n",
    "dfQuestions.select(mean(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(score)|\n",
      "+----------+\n",
      "|    361427|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//sum\n",
    "dfQuestions.select(sum(\"score\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------------+\n",
      "|owner_userid|avg(score)|max(answer_count)|\n",
      "+------------+----------+-----------------+\n",
      "|         268|      26.0|                1|\n",
      "|         136|      57.6|                9|\n",
      "|         123|      20.0|                3|\n",
      "+------------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Group by with statistics\n",
    "dfQuestions.filter(\"id > 400 and id < 450\")\n",
    "    .filter(\"owner_userid is not null\")\n",
    "    .join(dfTags,dfQuestions.col(\"id\").equalTo(dfTags.col(\"id\")))\n",
    "    .groupBy(dfQuestions.col(\"owner_userid\"))\n",
    "    .agg(avg(\"score\"),max(\"answer_count\"))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "|summary|               id|             score|     owner_userid|      answer_count|\n",
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "|  count|             9999|              9999|             7388|              9922|\n",
      "|   mean|33929.17081708171| 36.14631463146315|47389.99472116947|6.6232614392259626|\n",
      "| stddev|19110.09560532429|160.48316753972045|280943.1070344427| 9.069109116851138|\n",
      "|    min|                1|               -27|                1|                -5|\n",
      "|    max|            66037|              4443|          3431280|               316|\n",
      "+-------+-----------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfSummary: org.apache.spark.sql.DataFrame = [summary: string, id: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame Statistics using describe() method\n",
    "val dfSummary = dfQuestions.describe()\n",
    "dfSummary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between column score and answer_count = 0.3699847903294707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correlation: Double = 0.3699847903294707\n"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Correlation\n",
    "val correlation = dfQuestions.stat.corr(\"score\",\"answer_count\")\n",
    "println(s\"correlation between column score and answer_count = $correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance between column score and answer_count = 537.513381444165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "covariance: Double = 537.513381444165\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Covariance\n",
    "val covariance = dfQuestions.stat.cov(\"score\",\"answer_count\")\n",
    "println(s\"covariance between column score and answer_count = $covariance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|answer_count_freqItems|\n",
      "+----------------------+\n",
      "|  [23, 131, 77, 86,...|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfFrequentScore: org.apache.spark.sql.DataFrame = [answer_count_freqItems: array<int>]\n"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Frequent Items\n",
    "val dfFrequentScore = dfQuestions.stat.freqItems(Seq(\"answer_count\"))\n",
    "dfFrequentScore.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+---+---+---+---+---+---+---+---+---+\n",
      "|score_owner_userid|  1| 11| 13| 17|  2|  3|  4|  5|  8|  9|\n",
      "+------------------+---+---+---+---+---+---+---+---+---+---+\n",
      "|                56|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|\n",
      "|               472|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|                14|  0|  0|  0|  1|  0|  0|  0|  1|  0|  0|\n",
      "|                20|  0|  0|  0|  0|  0|  0|  0|  1|  0|  0|\n",
      "|               179|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|\n",
      "+------------------+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfScoreByUserid: org.apache.spark.sql.DataFrame = [score_owner_userid: string, 1: bigint ... 9 more fields]\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Crosstab\n",
    "val dfScoreByUserid = dfQuestions\n",
    "    .filter(\"owner_userid > 0 and owner_userid < 20\")\n",
    "    .stat\n",
    "    .crosstab(\"score\",\"owner_userid\")\n",
    "dfScoreByUserid.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|answer_count|count|\n",
      "+------------+-----+\n",
      "|          20|   34|\n",
      "|           5|  811|\n",
      "|          10|  272|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfQuestionsByAnswerCount: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, creation_date: timestamp ... 5 more fields]\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Stratified sampling using sampleBy\n",
    "val dfQuestionsByAnswerCount = dfQuestions\n",
    "    .filter(\"owner_userid > 0\")\n",
    "    .filter(\"answer_count in (5,10,20)\")\n",
    "\n",
    "dfQuestionsByAnswerCount.groupBy(\"answer_count\")\n",
    "    .count()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|answer_count|count|\n",
      "+------------+-----+\n",
      "|          20|   34|\n",
      "|           5|  400|\n",
      "|          10|   26|\n",
      "+------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fractionKeyMap: scala.collection.immutable.Map[Int,Double] = Map(5 -> 0.5, 10 -> 0.1, 20 -> 1.0)\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a fraction map where we are only interested:\n",
    "// - 50% of the rows that have answer_count = 5\n",
    "// - 10% of the rows that have answer_count = 10\n",
    "// - 100% of the rows that have answer_count = 20\n",
    "// Note also that fractions should be in the range [0, 1]\n",
    "\n",
    "val fractionKeyMap = Map(5->0.5, 10->0.1,20->1.0)\n",
    "\n",
    "dfQuestionsByAnswerCount\n",
    "    .stat\n",
    "    .sampleBy(\"answer_count\",fractionKeyMap,7L)\n",
    "    .groupBy(\"answer_count\")\n",
    "    .count().show()\n",
    "\n",
    "//randomseed == 7L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitles segments = WrappedArray(-27.0, 2.0, 4443.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quantiles: Array[Double] = Array(-27.0, 2.0, 4443.0)\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Approximate Quantile\n",
    "val quantiles = dfQuestions\n",
    "    .stat\n",
    "    .approxQuantile(\"score\",Array(0,0.5,1),0.25)\n",
    "println(s\"Quantitles segments = ${quantiles.toSeq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagsBloomFilter: org.apache.spark.util.sketch.BloomFilter = org.apache.spark.util.sketch.BloomFilterImpl@809c4023\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Bloom Filter\n",
    "val tagsBloomFilter = dfTags.stat.bloomFilter(\"tag\",1000L,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloom filter contains java tag = true\n"
     ]
    }
   ],
   "source": [
    "println(s\"bloom filter contains java tag = ${tagsBloomFilter.mightContain(\"java\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloom filter contains some unknown tag = false\n"
     ]
    }
   ],
   "source": [
    "println(s\"bloom filter contains some unknown tag = ${tagsBloomFilter.mightContain(\"unknown tag\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated frequency for tag java = 513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cmsTag: org.apache.spark.util.sketch.CountMinSketch = org.apache.spark.util.sketch.CountMinSketchImpl@431a88ed\n",
       "estimatedFrequency: Long = 513\n"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Count Min Sketch\n",
    "    // first parameter = the tag column of dataframe dfTags\n",
    "    // second parameter = 10% precision error factor\n",
    "    // third parameter = 90% confidence level\n",
    "    // fourth parameter = 37 as a random seed\n",
    "\n",
    "val cmsTag = dfTags.stat.countMinSketch(\"tag\", 0.1, 0.9, 37)\n",
    "val estimatedFrequency = cmsTag.estimateCount(\"java\")\n",
    "println(s\"Estimated frequency for tag java = $estimatedFrequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in sample dfTagsSample = 1948\n",
      "Number of rows in dfTags = 9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfTagsSample: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, tag: string]\n"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Sampling With Replacement\n",
    "    // with replacement = true\n",
    "    // number of rows to sample = 20%\n",
    "    // a random seed = 37L\n",
    "val dfTagsSample = dfTags.sample(true,0.2,37L)\n",
    "println(s\"Number of rows in sample dfTagsSample = ${dfTagsSample.count()}\")\n",
    "println(s\"Number of rows in dfTags = ${dfTags.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame Operations Introduction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfQuestions: org.apache.spark.sql.DataFrame = [owner_userid: string, tag: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfQuestions = dfQuestionCSV\n",
    "    .filter(\"score > 400 and score < 410\")\n",
    "    .join(dfTags,\"id\")\n",
    "    .select(\"owner_userid\",\"tag\",\"creation_date\",\"score\")\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// dfTags.show(2);dfQuestionCSV.show(2);dfQuestions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Tag\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Convert DataFrame row to Scala case class\n",
    "case class Tag(id: Int,tag: String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id| tag|\n",
      "+---+----+\n",
      "|  1|data|\n",
      "|  4|  c#|\n",
      "+---+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTags.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "import org.apache.spark.sql.Dataset\n",
       "dfTagsOfTag: org.apache.spark.sql.Dataset[Tag] = [id: int, tag: string]\n"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.Dataset\n",
    "val dfTagsOfTag: Dataset[Tag] = dfTags.as[Tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id = 1, tag = data\n",
      "id = 4, tag = c#\n",
      "id = 4, tag = winforms\n",
      "id = 4, tag = type-conversion\n",
      "id = 4, tag = decimal\n",
      "id = 4, tag = opacity\n",
      "id = 6, tag = html\n",
      "id = 6, tag = css\n",
      "id = 6, tag = css3\n",
      "id = 6, tag = internet-explorer-7\n"
     ]
    }
   ],
   "source": [
    "dfTagsOfTag\n",
    "    .take(10)\n",
    "    .foreach(t => println(s\"id = ${t.id}, tag = ${t.tag}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Question\n"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame row to Scala case class using map()\n",
    "case class Question(owner_userid: Int, tag: String,\n",
    "                   creationDate: java.sql.Timestamp, score: Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------------------+-----+\n",
      "|owner_userid|     tag|      creation_date|score|\n",
      "+------------+--------+-------------------+-----+\n",
      "|         131|  xdebug|2008-08-04 07:18:21|  405|\n",
      "|         131|phpstorm|2008-08-04 07:18:21|  405|\n",
      "+------------+--------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfQuestions.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toQuestion: (row: org.apache.spark.sql.Row)Question\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toQuestion(row: org.apache.spark.sql.Row): Question = {\n",
    "// to normalize our owner_userid data\n",
    "    val IntOf: String => Option[Int] = _ match {\n",
    "  case s if s == \"NA\" => None\n",
    "  case s => Some(s.toInt)\n",
    "    }\n",
    "    \n",
    "    import java.time._\n",
    "    val DateOf: String => java.sql.Timestamp = _ match {\n",
    "      case s => java.sql.Timestamp.valueOf(ZonedDateTime.parse(s).toLocalDateTime)\n",
    "    }\n",
    "\n",
    "    Question (\n",
    "      owner_userid = IntOf(row.getString(0)).getOrElse(-1),\n",
    "      tag = row.getString(1),\n",
    "      creationDate = DateOf(row.getString(2)),\n",
    "      score = row.getString(3).toInt\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "dfOfQuestion: org.apache.spark.sql.Dataset[Question] = [owner_userid: int, tag: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val dfOfQuestion: Dataset[Question] = dfQuestions.map(row => toQuestion(row))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|      tag|\n",
      "+---+---------+\n",
      "|  1|  so_java|\n",
      "|  1|   so_jsp|\n",
      "|  2|so_erlang|\n",
      "|  3| so_scala|\n",
      "|  4|  so_akka|\n",
      "+---+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "segTags: Seq[(Int, String)] = List((1,so_java), (1,so_jsp), (2,so_erlang), (3,so_scala), (4,so_akka))\n",
       "import spark.implicits._\n",
       "dfMoreTags: org.apache.spark.sql.DataFrame = [id: int, tag: string]\n"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create DataFrame from collection\n",
    "val segTags = Seq(\n",
    "    1 -> \"so_java\",\n",
    "    1 -> \"so_jsp\",\n",
    "    2 -> \"so_erlang\",\n",
    "    3 -> \"so_scala\",\n",
    "    4 -> \"so_akka\"\n",
    ")\n",
    "\n",
    "import spark.implicits._\n",
    "val dfMoreTags = segTags.toDF(\"id\",\"tag\")\n",
    "dfMoreTags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|     tag|\n",
      "+---+--------+\n",
      "|  1|    data|\n",
      "|  1| so_java|\n",
      "|  1|  so_jsp|\n",
      "|  3|so_scala|\n",
      "+---+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfUnionOfTags: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: int, tag: string]\n"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame Union\n",
    "val dfUnionOfTags = dfTags.union(dfMoreTags)\n",
    "    .filter(\"id in (1,3)\")\n",
    "dfUnionOfTags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|     tag|\n",
      "+---+--------+\n",
      "|  3|so_scala|\n",
      "|  1| so_java|\n",
      "|  1|  so_jsp|\n",
      "+---+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dfIntersectionTags: Unit = ()\n"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame Intersection\n",
    "val dfIntersectionTags = dfMoreTags.intersect(dfUnionOfTags).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "dfSplitColumn: org.apache.spark.sql.DataFrame = [id: int, tag: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Append column to DataFrame using withColumn()\n",
    "import org.apache.spark.sql.functions._\n",
    "val dfSplitColumn = dfMoreTags\n",
    "    .withColumn(\"tmp\",split($\"tag\",\"_\"))\n",
    "    .select(\n",
    "    $\"id\",\n",
    "    $\"tag\",\n",
    "    $\"tmp\".getItem(0).as(\"so_prefix\"),\n",
    "    $\"tmp\".getItem(1).as(\"so_tag\"))\n",
    "    .drop(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+------+\n",
      "| id|      tag|so_prefix|so_tag|\n",
      "+---+---------+---------+------+\n",
      "|  1|  so_java|       so|  java|\n",
      "|  1|   so_jsp|       so|   jsp|\n",
      "|  2|so_erlang|       so|erlang|\n",
      "|  3| so_scala|       so| scala|\n",
      "|  4|  so_akka|       so|  akka|\n",
      "+---+---------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSplitColumn.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. http://localhost:8888/notebooks/Downloads/backUp/dataset/GPS/%F0%9F%9A%98RAI%20%E2%9C%A8.ipynb\n",
    "2. http://localhost:8888/notebooks/Downloads/backUp/dataset/GPS/%F0%9F%A6%88GPSpipeline.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
